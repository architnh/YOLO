# -*- coding: utf-8 -*-
"""Final-cnn-cifar-10-classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SNN09GVn_q6_c2Oke6tqNXYcIRW2dRoK

1. <a href="#load"> Loading Data </a>
2. <a href="#prep"> Pre-processing </a>
3. <a href="#bmod"> Build Model </a>
4. <a href="#eval"> Evaluate Model </a>
5. <a href="#pred"> Predict </a>
"""

import os
import itertools
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Hide all TensorFlow debugging logs

import numpy as np
import matplotlib.pyplot as plt

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
from tensorflow.keras.datasets import cifar100
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.applications import densenet
from tensorflow.keras.models import Sequential, Model, load_model
from tensorflow.keras.layers import Activation, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard

from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
import keras
import tensorflow as tf
from keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import optimizers
from keras.callbacks import EarlyStopping
import keras.backend as K
from keras.constraints import max_norm
from PIL import Image

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from tensorflow import keras
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import classification_report, confusion_matrix

"""# <a id="load">Loading Data</a>

CIFAR-10 is a dataset of 50,000 32x32 color training images, labeled over 10 classes
"""

from tensorflow.keras.datasets import cifar10

(x_train, y_train), (x_test, y_test) = cifar10.load_data()

print(x_train.shape)
print(y_train.shape)
print(x_test.shape)
print(y_test.shape)

fig = plt.figure(figsize=(8, 8))
columns = 6
rows = 4
for i in range(1, columns*rows +1):
    img = x_train[i]
    fig.add_subplot(rows, columns, i)
    plt.axis('off')
    plt.imshow(img)
plt.show()

"""# <a id="prep"> Pre-processing </a>"""

print(x_train.max())
print(x_test.max())

x_train = x_train/225
x_test = x_test/255

y_cat_train = to_categorical(y_train, 10)
y_cat_test = to_categorical(y_test,10)

"""# <a id="bmod"> Build Model </a>"""

model = Sequential()

model=keras.models.Sequential()
model.add(keras.layers.Conv2D(filters=128,kernel_size=(3,3),activation='relu'))
model.add(keras.layers.BatchNormalization(momentum=0.8))
model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))
#model.add(keras.layers.Dropout(0.5))
model.add(keras.layers.Conv2D(filters=64,kernel_size=(3,3),activation='relu'))
model.add(keras.layers.BatchNormalization(momentum=0.8))
model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))
#model.add(keras.layers.Dropout(0.5))
model.add(keras.layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu'))
model.add(keras.layers.BatchNormalization(momentum=0.8))
model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))
#model.add(keras.layers.Dropout(0.5))
model.add(keras.layers.Flatten())
model.add(keras.layers.Dense(512,activation='softmax'))
model.add(keras.layers.Dense(10,activation='sigmoid'))


# sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True) 
adam = optimizers.Adam(lr=0.001)
#earlystopping = EarlyStopping(monitor ="val_accuracy",
#                              mode = 'auto', patience = 6,
#                              restore_best_weights = True)

model.compile(loss='categorical_crossentropy',
                     optimizer=adam,
                     metrics=['accuracy'])

#early_stop = EarlyStopping(monitor='val_loss',patience=3)

model.fit(x_train,
          y_cat_train,
          batch_size=64,
          epochs=30,
          validation_data=(x_test,y_cat_test),
          #callbacks=[early_stop]
          )

model.save("Updated_Cifar10_CNN_model.h5")

losses = pd.DataFrame(model.history.history)

losses[['loss','val_loss']].plot()

losses[['accuracy','val_accuracy']].plot()

"""# <a id="eval"> Evaluate Model </a>"""

print(model.metrics_names)
print(model.evaluate(x_test,y_cat_test,verbose=0))

predictions = np.argmax(model.predict(x_test), axis=-1)

print(classification_report(y_test,predictions))

confusion_matrix(y_test,predictions)

"""# <a id="pred"> Predict </a>"""

classes = [0,1,2,3,4,5,6,7,8,9]
class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']
# https://www.cs.toronto.edu/~kriz/cifar.html

d = dict(zip(classes, class_names))

my_image = x_test[1005]

plt.imshow(my_image)

input_img = my_image.reshape(1,32,32,3)

predictions = np.argmax(model.predict(input_img), axis=-1)[0]

print(f"True class: {d[y_test[1005][0]]} \n\nPredicted class: {d[predictions]}")